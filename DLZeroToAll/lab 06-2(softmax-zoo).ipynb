{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "795f2a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.random.set_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc86eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data-04-zoo.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd36961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 16) (101, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b21560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensor \n",
    "X = tf.constant(x_data, dtype=tf.float32)\n",
    "Y = tf.constant(y_data, dtype=tf.float32)\n",
    "\n",
    "nb_classes = 7\n",
    "W = tf.Variable(tf.random.normal([16, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([nb_classes]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "458231bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot\n",
    "Y_one_hot = tf.one_hot(y_data, nb_classes)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a703eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits\n",
    "def logits(X):\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "# hypothesis\n",
    "def hypothesis(X):\n",
    "    return tf.nn.softmax(logits(X))\n",
    "\n",
    "# cost function\n",
    "def cost_function(X, Y):\n",
    "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits(X), labels=tf.stop_gradient([Y_one_hot])))\n",
    "\n",
    "# optimize/minimize\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66979f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted(hypothesis):\n",
    "    return tf.argmax(hypothesis, 1)\n",
    "\n",
    "def accuracy(predict, Y):\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(predict, tf.argmax(Y_one_hot, 1)), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22ea441a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.42258 0.16831683\n",
      "20 1.4408512 0.56435645\n",
      "40 0.93945456 0.65346533\n",
      "60 0.73111403 0.7128713\n",
      "80 0.6042888 0.76237625\n",
      "100 0.5194158 0.7920792\n",
      "120 0.45817316 0.84158415\n",
      "140 0.4114203 0.8811881\n",
      "160 0.3742679 0.8910891\n",
      "180 0.34388497 0.9009901\n",
      "200 0.31850094 0.9108911\n",
      "220 0.29693654 0.9306931\n",
      "240 0.27836695 0.9405941\n",
      "260 0.26219323 0.9405941\n",
      "280 0.24796787 0.9405941\n",
      "300 0.2353488 0.9405941\n",
      "320 0.22406967 0.9405941\n",
      "340 0.21392024 0.95049506\n",
      "360 0.20473228 0.95049506\n",
      "380 0.19636978 0.95049506\n",
      "400 0.1887214 0.95049506\n",
      "420 0.18169549 0.95049506\n",
      "440 0.1752157 0.95049506\n",
      "460 0.16921805 0.95049506\n",
      "480 0.1636483 0.95049506\n",
      "500 0.15846038 0.96039605\n",
      "520 0.15361479 0.96039605\n",
      "540 0.14907752 0.980198\n",
      "560 0.14481884 0.990099\n",
      "580 0.1408131 0.990099\n",
      "600 0.13703758 0.990099\n",
      "620 0.13347238 0.990099\n",
      "640 0.13009986 0.990099\n",
      "660 0.12690437 0.990099\n",
      "680 0.12387183 0.990099\n",
      "700 0.12098984 0.990099\n",
      "720 0.11824707 0.990099\n",
      "740 0.11563341 0.990099\n",
      "760 0.113139704 0.990099\n",
      "780 0.11075759 0.990099\n",
      "800 0.10847964 1.0\n",
      "820 0.10629889 1.0\n",
      "840 0.10420911 1.0\n",
      "860 0.102204524 1.0\n",
      "880 0.100279845 1.0\n",
      "900 0.09843039 1.0\n",
      "920 0.09665157 1.0\n",
      "940 0.09493931 1.0\n",
      "960 0.09328986 1.0\n",
      "980 0.0916997 1.0\n",
      "1000 0.09016556 1.0\n",
      "1020 0.08868448 1.0\n",
      "1040 0.08725364 1.0\n",
      "1060 0.08587049 1.0\n",
      "1080 0.08453252 1.0\n",
      "1100 0.08323754 1.0\n",
      "1120 0.08198343 1.0\n",
      "1140 0.08076822 1.0\n",
      "1160 0.07959009 1.0\n",
      "1180 0.07844726 1.0\n",
      "1200 0.07733817 1.0\n",
      "1220 0.07626126 1.0\n",
      "1240 0.07521514 1.0\n",
      "1260 0.07419842 1.0\n",
      "1280 0.073209874 1.0\n",
      "1300 0.07224827 1.0\n",
      "1320 0.071312584 1.0\n",
      "1340 0.07040164 1.0\n",
      "1360 0.0695145 1.0\n",
      "1380 0.06865018 1.0\n",
      "1400 0.06780781 1.0\n",
      "1420 0.06698653 1.0\n",
      "1440 0.06618557 1.0\n",
      "1460 0.0654041 1.0\n",
      "1480 0.064641446 1.0\n",
      "1500 0.06389692 1.0\n",
      "1520 0.06316981 1.0\n",
      "1540 0.062459588 1.0\n",
      "1560 0.061765585 1.0\n",
      "1580 0.061087277 1.0\n",
      "1600 0.060424082 1.0\n",
      "1620 0.05977553 1.0\n",
      "1640 0.059141155 1.0\n",
      "1660 0.058520403 1.0\n",
      "1680 0.057912894 1.0\n",
      "1700 0.057318196 1.0\n",
      "1720 0.056735866 1.0\n",
      "1740 0.056165557 1.0\n",
      "1760 0.055606864 1.0\n",
      "1780 0.055059455 1.0\n",
      "1800 0.05452294 1.0\n",
      "1820 0.053997025 1.0\n",
      "1840 0.053481396 1.0\n",
      "1860 0.052975766 1.0\n",
      "1880 0.05247981 1.0\n",
      "1900 0.051993225 1.0\n",
      "1920 0.05151581 1.0\n",
      "1940 0.051047277 1.0\n",
      "1960 0.050587352 1.0\n",
      "1980 0.05013583 1.0\n",
      "2000 0.049692467 1.0\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_cost = cost_function(X, Y)\n",
    "    gradients = tape.gradient(current_cost, [W, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        p = predicted(hypothesis(X))\n",
    "        print(step, current_cost.numpy(), accuracy(p, Y).numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
