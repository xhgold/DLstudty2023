{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a759779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f108819f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(None,) dtype=float32, numpy=array([1., 2., 3., 4., 5.], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X and Y train data\n",
    "initial_value = [0.0]\n",
    "X = tf.Variable(initial_value, dtype = tf.float32, shape=[None]) \n",
    "Y = tf.Variable(initial_value, dtype = tf.float32, shape=[None])\n",
    "X.assign([1, 2, 3, 4, 5])\n",
    "Y.assign([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6937bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(5., name = 'weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c4d9922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 144.86119 4.2025833 [-1.588858]\n",
      "20 0.84916925 1.6068015 [-2.1456978]\n",
      "40 0.7390224 1.5562844 [-2.0081599]\n",
      "60 0.64539397 1.5198044 [-1.8766576]\n",
      "80 0.56362736 1.4857615 [-1.7537538]\n",
      "100 0.49221978 1.4539487 [-1.638899]\n",
      "120 0.42985925 1.4242193 [-1.5315661]\n",
      "140 0.37539926 1.3964368 [-1.4312625]\n",
      "160 0.32783902 1.3704737 [-1.337528]\n",
      "180 0.28630418 1.3462112 [-1.2499323]\n",
      "200 0.25003153 1.3235376 [-1.168073]\n",
      "220 0.21835442 1.3023489 [-1.0915751]\n",
      "240 0.1906906 1.2825477 [-1.0200871]\n",
      "260 0.16653156 1.2640435 [-0.9532808]\n",
      "280 0.14543322 1.246751 [-0.8908496]\n",
      "300 0.12700787 1.2305912 [-0.83250713]\n",
      "320 0.11091693 1.2154895 [-0.7779855]\n",
      "340 0.09686461 1.2013769 [-0.72703457]\n",
      "360 0.08459256 1.1881887 [-0.67942053]\n",
      "380 0.073875226 1.1758639 [-0.63492465]\n",
      "400 0.06451577 1.1643463 [-0.59334284]\n",
      "420 0.056342136 1.1535833 [-0.55448437]\n",
      "440 0.04920405 1.143525 [-0.5181708]\n",
      "460 0.042970262 1.1341255 [-0.48423535]\n",
      "480 0.037526224 1.1253415 [-0.4525224]\n",
      "500 0.032771897 1.1171328 [-0.42288634]\n",
      "520 0.028619949 1.1094617 [-0.39519122]\n",
      "540 0.02499404 1.1022928 [-0.36930984]\n",
      "560 0.021827463 1.0955937 [-0.34512344]\n",
      "580 0.01906211 1.0893332 [-0.322521]\n",
      "600 0.016647097 1.0834826 [-0.30139884]\n",
      "620 0.014538015 1.0780153 [-0.2816599]\n",
      "640 0.012696156 1.0729059 [-0.26321375]\n",
      "660 0.011087639 1.0681313 [-0.24597567]\n",
      "680 0.009682942 1.0636694 [-0.22986655]\n",
      "700 0.008456154 1.0594996 [-0.2148124]\n",
      "720 0.0073848306 1.0556029 [-0.20074415]\n",
      "740 0.0064492105 1.0519614 [-0.18759726]\n",
      "760 0.005632155 1.0485584 [-0.1753113]\n",
      "780 0.004918602 1.0453782 [-0.16382997]\n",
      "800 0.004295438 1.0424064 [-0.15310064]\n",
      "820 0.0037512407 1.0396291 [-0.14307393]\n",
      "840 0.0032759856 1.0370338 [-0.13370389]\n",
      "860 0.0028609494 1.0346085 [-0.1249475]\n",
      "880 0.0024984821 1.032342 [-0.11676455]\n",
      "900 0.002181953 1.0302237 [-0.10911754]\n",
      "920 0.0019055081 1.0282444 [-0.10197128]\n",
      "940 0.001664089 1.0263946 [-0.09529305]\n",
      "960 0.0014532593 1.024666 [-0.08905218]\n",
      "980 0.0012691485 1.0230507 [-0.08322009]\n",
      "1000 0.0011083492 1.0215411 [-0.07776994]\n",
      "1020 0.0009679297 1.0201302 [-0.07267668]\n",
      "1040 0.00084530225 1.018812 [-0.06791698]\n",
      "1060 0.0007382071 1.0175799 [-0.06346902]\n",
      "1080 0.0006446812 1.0164286 [-0.05931241]\n",
      "1100 0.0005630066 1.0153527 [-0.05542801]\n",
      "1120 0.00049167435 1.0143472 [-0.05179795]\n",
      "1140 0.00042938712 1.0134076 [-0.0484057]\n",
      "1160 0.00037498662 1.0125295 [-0.04523559]\n",
      "1180 0.00032747895 1.011709 [-0.04227309]\n",
      "1200 0.00028598952 1.0109422 [-0.03950462]\n",
      "1220 0.00024976078 1.0102257 [-0.03691753]\n",
      "1240 0.00021811594 1.0095558 [-0.03449982]\n",
      "1260 0.00019048213 1.00893 [-0.03224031]\n",
      "1280 0.0001663471 1.0083452 [-0.03012881]\n",
      "1300 0.00014527238 1.0077987 [-0.02815563]\n",
      "1320 0.00012686814 1.007288 [-0.02631168]\n",
      "1340 0.00011079349 1.0068105 [-0.02458851]\n",
      "1360 9.675848e-05 1.0063646 [-0.02297816]\n",
      "1380 8.449863e-05 1.0059478 [-0.0214733]\n",
      "1400 7.379453e-05 1.0055583 [-0.02006701]\n",
      "1420 6.44447e-05 1.0051943 [-0.01875283]\n",
      "1440 5.627955e-05 1.0048541 [-0.01752474]\n",
      "1460 4.9149192e-05 1.0045362 [-0.01637703]\n",
      "1480 4.2922453e-05 1.0042391 [-0.01530447]\n",
      "1500 3.7484806e-05 1.0039614 [-0.0143022]\n",
      "1520 3.273566e-05 1.003702 [-0.01336553]\n",
      "1540 2.8588393e-05 1.0034596 [-0.01249022]\n",
      "1560 2.496711e-05 1.0032331 [-0.01167224]\n",
      "1580 2.1804159e-05 1.0030214 [-0.01090787]\n",
      "1600 1.9041323e-05 1.0028235 [-0.01019353]\n",
      "1620 1.6629134e-05 1.0026386 [-0.00952597]\n",
      "1640 1.452333e-05 1.0024658 [-0.00890214]\n",
      "1660 1.2682731e-05 1.0023043 [-0.00831919]\n",
      "1680 1.10759665e-05 1.0021534 [-0.00777435]\n",
      "1700 9.672577e-06 1.0020124 [-0.00726526]\n",
      "1720 8.447192e-06 1.0018805 [-0.00678945]\n",
      "1740 7.3771635e-06 1.0017575 [-0.00634482]\n",
      "1760 6.4425753e-06 1.0016423 [-0.0059293]\n",
      "1780 5.626428e-06 1.0015347 [-0.00554098]\n",
      "1800 4.9135465e-06 1.0014342 [-0.0051781]\n",
      "1820 4.290737e-06 1.0013404 [-0.00483903]\n",
      "1840 3.7476166e-06 1.0012525 [-0.00452216]\n",
      "1860 3.2727598e-06 1.0011706 [-0.00422609]\n",
      "1880 2.8581346e-06 1.001094 [-0.00394936]\n",
      "1900 2.4961605e-06 1.0010223 [-0.00369072]\n",
      "1920 2.1798576e-06 1.0009555 [-0.00344907]\n",
      "1940 1.9039242e-06 1.0008929 [-0.00322328]\n",
      "1960 1.6628195e-06 1.0008345 [-0.00301232]\n",
      "1980 1.4522062e-06 1.0007799 [-0.0028151]\n",
      "2000 1.2684793e-06 1.0007287 [-0.00263082]\n"
     ]
    }
   ],
   "source": [
    "# hypothesis\n",
    "def hypothesis(X):\n",
    "    return X * W + b\n",
    "\n",
    "# cost/loss function\n",
    "def cost_function(hypothesis, Y):\n",
    "    return tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# optimizer(Gradient Descent)\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.01) \n",
    "\n",
    "# Training\n",
    "for step in range(2001):\n",
    "    with tf.GradientTape() as tape: #Auto differentiation\n",
    "        current_cost = cost_function(hypothesis(X), Y)\n",
    "    gradients = tape.gradient(current_cost, [W, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(step, current_cost.numpy(), W.numpy(), b.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
