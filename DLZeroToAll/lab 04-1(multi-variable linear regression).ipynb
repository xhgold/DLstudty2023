{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19176aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0831f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[float(random.randint(70, 100)) for _ in range(3)] for _ in range(5)]\n",
    "y_data = [[float(random.randint(140, 190))] for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef0ac40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_data\n",
    "Y = y_data\n",
    "\n",
    "W = tf.Variable(tf.random.normal(([3, 1]), name = 'weight'))\n",
    "b = tf.Variable(tf.random.normal(([1]), name = 'bias'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7caf1a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis\n",
    "def hypothesis(X):\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "# cost function\n",
    "def cost_function(hypothesis, Y):\n",
    "    return tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# optimize(Gradien Descent)\n",
    "optimizer = tf.optimizers.SGD(learning_rate =1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3b75d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 73394.34\n",
      "100 117.92704\n",
      "200 105.36617\n",
      "300 95.36543\n",
      "400 87.25183\n",
      "500 80.54357\n",
      "600 74.89534\n",
      "700 70.05812\n",
      "800 65.851555\n",
      "900 62.144276\n",
      "1000 58.83957\n",
      "1100 55.865654\n",
      "1200 53.16874\n",
      "1300 50.70787\n",
      "1400 48.451164\n",
      "1500 46.373848\n",
      "1600 44.455837\n",
      "1700 42.68072\n",
      "1800 41.03492\n",
      "1900 39.50695\n",
      "2000 38.086914\n",
      "2100 36.765934\n",
      "2200 35.53658\n",
      "2300 34.39175\n",
      "2400 33.325314\n",
      "2500 32.331776\n",
      "2600 31.40572\n",
      "2700 30.5427\n",
      "2800 29.738033\n",
      "2900 28.9879\n",
      "3000 28.288553\n",
      "3100 27.63644\n",
      "3200 27.028421\n",
      "3300 26.46139\n",
      "3400 25.932693\n",
      "3500 25.439672\n",
      "3600 24.979929\n",
      "3700 24.551239\n",
      "3800 24.151367\n",
      "3900 23.778507\n",
      "4000 23.43086\n",
      "4100 23.106615\n",
      "4200 22.804241\n",
      "4300 22.522234\n",
      "4400 22.259281\n",
      "4500 22.014088\n",
      "4600 21.785318\n",
      "4700 21.572117\n",
      "4800 21.373226\n",
      "4900 21.18781\n",
      "5000 21.01475\n",
      "5100 20.853468\n",
      "5200 20.703062\n",
      "5300 20.56277\n",
      "5400 20.431936\n",
      "5500 20.30995\n",
      "5600 20.19614\n",
      "5700 20.090094\n",
      "5800 19.991123\n",
      "5900 19.89888\n",
      "6000 19.812866\n",
      "6100 19.732567\n",
      "6200 19.65775\n",
      "6300 19.587963\n",
      "6400 19.522867\n",
      "6500 19.462173\n",
      "6600 19.405586\n",
      "6700 19.352728\n",
      "6800 19.303505\n",
      "6900 19.2577\n",
      "7000 19.214832\n",
      "7100 19.174936\n",
      "7200 19.13766\n",
      "7300 19.103\n",
      "7400 19.070583\n",
      "7500 19.040333\n",
      "7600 19.012169\n",
      "7700 18.985878\n",
      "7800 18.961376\n",
      "7900 18.938574\n",
      "8000 18.917278\n",
      "8100 18.897408\n",
      "8200 18.87886\n",
      "8300 18.861542\n",
      "8400 18.84541\n",
      "8500 18.83037\n",
      "8600 18.816364\n",
      "8700 18.803268\n",
      "8800 18.791124\n",
      "8900 18.77976\n",
      "9000 18.769104\n",
      "9100 18.759197\n",
      "9200 18.750011\n",
      "9300 18.741432\n",
      "9400 18.733347\n",
      "9500 18.725887\n",
      "9600 18.718939\n",
      "9700 18.712347\n",
      "9800 18.706339\n",
      "9900 18.700663\n",
      "10000 18.6954\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for step in range(10001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_cost = cost_function(hypothesis(X), Y)\n",
    "    gradients = tape.gradient(current_cost, [W, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step, current_cost.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82b8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
